{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import random \n",
    "import re\n",
    "import cv2\n",
    "\n",
    "from random import shuffle\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "from skimage.transform import rescale\n",
    "from skimage.transform import rotate\n",
    "from skimage import exposure\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, BatchNormalization,SpatialDropout2D,Conv2DTranspose,concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "from tensorflow.keras.layers import Bidirectional,ConvLSTM2D,LSTM\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_nsre = re.compile('([0-9]+)')\n",
    "def natural_sort_key(s):\n",
    "    return [int(text) if text.isdigit() else text.lower()\n",
    "            for text in re.split(_nsre, s)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_dir(lab_file,type_file,set_file):\n",
    "    data_path='../DL_course_data/'\n",
    "    set_dir=os.path.join(data_path, lab_file,type_file,set_file)\n",
    "    return set_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_set_list(set_dir):\n",
    "    set_list = os.listdir(set_dir)\n",
    "    set_list.sort(key=natural_sort_key)\n",
    "    return set_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_dir(data_list,data_dir):\n",
    "    new_data=[]\n",
    "    for x in data_list:\n",
    "        new = os.path.join(data_dir,x)\n",
    "        new_data.append(new)\n",
    "    return new_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(lab_file,type_file,train_percent):\n",
    "    img_dir1 = create_set_dir(lab_file,type_file,'Image')\n",
    "    img_dir2 = create_set_dir(lab_file,type_file,'Mask')\n",
    "\n",
    "    image_list = create_set_list(img_dir1)\n",
    "    mask_list = create_set_list(img_dir2)\n",
    "\n",
    "    index_position = list(zip(image_list,mask_list))\n",
    "    random.shuffle(index_position)\n",
    "    image_list[:],mask_list[:] = zip(*index_position)\n",
    "\n",
    "    length = len(image_list)\n",
    "    train_length = int(length*train_percent)\n",
    "\n",
    "    x_train = image_list[0:train_length]\n",
    "    y_train = mask_list[0:train_length]\n",
    "    x_test = image_list[train_length:]\n",
    "    y_test = mask_list[train_length:]\n",
    "    \n",
    "    x_train = list_dir(x_train,img_dir1)\n",
    "    y_train = list_dir(y_train,img_dir2)\n",
    "    x_test = list_dir(x_test,img_dir1)\n",
    "    y_test = list_dir(y_test,img_dir2)\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_list,img_w,img_h,img_ch,mask=False):\n",
    "    tab = np.zeros((len(data_list),img_w,img_h,img_ch),dtype='float32')\n",
    "    for i in range(len(data_list)):\n",
    "        Img = cv2.imread(data_list[i],0)\n",
    "        Img = cv2.resize(Img,(img_w, img_h))\n",
    "        Img = Img.reshape(img_w,img_h)/255\n",
    "        if mask:\n",
    "            Img[Img>0]=1\n",
    "            Img[Img!=1]=0\n",
    "        tab[i,:,:,0]=Img\n",
    "    return tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(image_set,mask_set,dictionary_augmentation,batch_size):\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**dictionary_augmentation)\n",
    "    mask_datagen = ImageDataGenerator(**dictionary_augmentation)\n",
    "\n",
    "    image_generator = image_datagen.flow(\n",
    "    image_set,\n",
    "    y=None,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=1)\n",
    "    \n",
    "    mask_generator = mask_datagen.flow(\n",
    "    mask_set,\n",
    "    y=None,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    seed=1)\n",
    "    train_generator=(pair for pair in zip(image_generator,mask_generator))\n",
    "    \n",
    "    \n",
    "    STEP_SIZE_TRAIN=(len(image_set)+len(mask_set))//batch_size\n",
    "    \n",
    "    return train_generator,STEP_SIZE_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(InputLayer,base_dense,BatchNorm=False):\n",
    "    if BatchNorm ==True:\n",
    "        conv1 = Conv2D(base_dense,(3,3),strides = (1,1), padding = \"same\")(InputLayer)\n",
    "        batch1 = BatchNormalization()(conv1)\n",
    "        act1 = Activation('relu')(batch1)\n",
    "        conv2 = Conv2D(base_dense,(3,3),strides = (1,1), padding = \"same\")(act1)\n",
    "        batch2 = BatchNormalization()(conv2)\n",
    "        act2 = Activation('relu')(batch2)\n",
    "\n",
    "    else:\n",
    "        conv1 = Conv2D(base_dense,(3,3),strides = (1,1), padding = \"same\", activation=\"relu\")(InputLayer)\n",
    "        conv2 = Conv2D(base_dense,(3,3),strides = (1,1), padding = \"same\", activation=\"relu\")(conv1)\n",
    "    return conv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(base_dense,img_w,img_h,img_ch,dropout=False,dr=0.2):\n",
    "    input_size = (img_w, img_h,img_ch)\n",
    "    input_layer = Input(shape=input_size, name='input_layer')\n",
    "    \n",
    "    if dropout==True:\n",
    "        conv1 = conv_block(input_layer,base_dense,BatchNorm=False)\n",
    "        pool1 = MaxPooling2D((2,2))(conv1)\n",
    "        pool1 = Dropout(dr)(pool1)\n",
    "\n",
    "        conv2 = conv_block(pool1,base_dense*2,BatchNorm=False)\n",
    "        pool2 = MaxPooling2D((2,2))(conv2)\n",
    "        pool2 = Dropout(dr)(pool2)\n",
    "\n",
    "        conv3 = conv_block(pool2,base_dense*4,BatchNorm=False)\n",
    "        pool3 = MaxPooling2D((2,2))(conv3)\n",
    "        pool3 = Dropout(dr)(pool3)\n",
    "\n",
    "        conv4 = conv_block(pool3,base_dense*8,BatchNorm=False)\n",
    "        pool4 = MaxPooling2D((2,2))(conv4)\n",
    "        pool4 = Dropout(dr)(pool4)\n",
    "\n",
    "        #middle\n",
    "        convm = conv_block(pool4,base_dense*16,BatchNorm=False)\n",
    "\n",
    "        #deconvolution\n",
    "        deconv1 = Conv2DTranspose(base_dense*8,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(convm)\n",
    "        uconv1=concatenate([deconv1,conv4])\n",
    "        uconv1=Dropout(dr)(uconv1)\n",
    "        uconv1=conv_block(uconv1,base_dense*8,BatchNorm=False)\n",
    "\n",
    "        deconv2 = Conv2DTranspose(base_dense*4,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv1)\n",
    "        uconv2=concatenate([deconv2,conv3])\n",
    "        uconv2=Dropout(dr)(uconv2)\n",
    "        uconv2=conv_block(uconv2,base_dense*4,BatchNorm=False)\n",
    "\n",
    "        deconv3= Conv2DTranspose(base_dense*2,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv2)\n",
    "        uconv3=concatenate([deconv3,conv2])\n",
    "        uconv3=Dropout(dr)(uconv3)\n",
    "        uconv3=conv_block(uconv3,base_dense*2,BatchNorm=False)\n",
    "\n",
    "        deconv4 = Conv2DTranspose(base_dense,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv3)\n",
    "        uconv4=concatenate([deconv4,conv1])\n",
    "        uconv4=Dropout(dr)(uconv4)\n",
    "        uconv4=conv_block(uconv4,base_dense,BatchNorm=False)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        conv1 = conv_block(input_layer,base_dense,BatchNorm=False)\n",
    "        pool1 = MaxPooling2D((2,2))(conv1)\n",
    "\n",
    "        conv2 = conv_block(pool1,base_dense*2,BatchNorm=False)\n",
    "        pool2 = MaxPooling2D((2,2))(conv2)\n",
    "\n",
    "        conv3 = conv_block(pool2,base_dense*4,BatchNorm=False)\n",
    "        pool3 = MaxPooling2D((2,2))(conv3)\n",
    "\n",
    "        conv4 = conv_block(pool3,base_dense*8,BatchNorm=False)\n",
    "        pool4 = MaxPooling2D((2,2))(conv4)\n",
    "\n",
    "        #middle\n",
    "        convm = conv_block(pool4,base_dense*16,BatchNorm=False)\n",
    "\n",
    "        #deconvolution\n",
    "        deconv1 = Conv2DTranspose(base_dense*8,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(convm)\n",
    "        uconv1=concatenate([deconv1,conv4])\n",
    "        uconv1=conv_block(uconv1,base_dense*8,BatchNorm=False)\n",
    "\n",
    "        deconv2 = Conv2DTranspose(base_dense*4,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv1)\n",
    "        uconv2=concatenate([deconv2,conv3])\n",
    "        uconv2=conv_block(uconv2,base_dense*4,BatchNorm=False)\n",
    "\n",
    "        deconv3= Conv2DTranspose(base_dense*2,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv2)\n",
    "        uconv3=concatenate([deconv3,conv2])\n",
    "        uconv3=conv_block(uconv3,base_dense*2,BatchNorm=False)\n",
    "\n",
    "        deconv4 = Conv2DTranspose(base_dense,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv3)\n",
    "        uconv4=concatenate([deconv4,conv1])\n",
    "        uconv4=conv_block(uconv4,base_dense,BatchNorm=False)\n",
    "        \n",
    "    output_layer=Conv2D(1,(1,1),padding='same',activation='sigmoid',name='output_layer')(uconv4)\n",
    "    \n",
    "    model=Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_batch(base_dense,img_w,img_h,img_ch,dropout=False,dr=0.2):\n",
    "    input_size = (img_w, img_h,img_ch)\n",
    "    input_layer = Input(shape=input_size, name='input_layer')\n",
    "    \n",
    "    if dropout==True:\n",
    "        conv1 = conv_block(input_layer,base_dense,BatchNorm=True)\n",
    "        pool1 = MaxPooling2D((2,2))(conv1)\n",
    "        pool1 = Dropout(dr)(pool1)\n",
    "\n",
    "        conv2 = conv_block(pool1,base_dense*2,BatchNorm=True)\n",
    "        pool2 = MaxPooling2D((2,2))(conv2)\n",
    "        pool2 = Dropout(dr)(pool2)\n",
    "\n",
    "        conv3 = conv_block(pool2,base_dense*4,BatchNorm=True)\n",
    "        pool3 = MaxPooling2D((2,2))(conv3)\n",
    "        pool3 = Dropout(dr)(pool3)\n",
    "\n",
    "        conv4 = conv_block(pool3,base_dense*8,BatchNorm=True)\n",
    "        pool4 = MaxPooling2D((2,2))(conv4)\n",
    "        pool4 = Dropout(dr)(pool4)\n",
    "\n",
    "        #middle\n",
    "        convm = conv_block(pool4,base_dense*16,BatchNorm=True)\n",
    "\n",
    "        #deconvolution\n",
    "        deconv1 = Conv2DTranspose(base_dense*8,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(convm)\n",
    "        uconv1=concatenate([deconv1,conv4])\n",
    "        uconv1=Dropout(dr)(uconv1)\n",
    "        uconv1=conv_block(uconv1,base_dense*8,BatchNorm=True)\n",
    "\n",
    "        deconv2 = Conv2DTranspose(base_dense*4,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv1)\n",
    "        uconv2=concatenate([deconv2,conv3])\n",
    "        uconv2=Dropout(dr)(uconv2)\n",
    "        uconv2=conv_block(uconv2,base_dense*4,BatchNorm=True)\n",
    "\n",
    "        deconv3= Conv2DTranspose(base_dense*2,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv2)\n",
    "        uconv3=concatenate([deconv3,conv2])\n",
    "        uconv3=Dropout(dr)(uconv3)\n",
    "        uconv3=conv_block(uconv3,base_dense*2,BatchNorm=True)\n",
    "\n",
    "        deconv4 = Conv2DTranspose(base_dense,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv3)\n",
    "        uconv4=concatenate([deconv4,conv1])\n",
    "        uconv4=Dropout(dr)(uconv4)\n",
    "        uconv4=conv_block(uconv4,base_dense,BatchNorm=True)\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        conv1 = conv_block(input_layer,base_dense,BatchNorm=True)\n",
    "        pool1 = MaxPooling2D((2,2))(conv1)\n",
    "\n",
    "        conv2 = conv_block(pool1,base_dense*2,BatchNorm=True)\n",
    "        pool2 = MaxPooling2D((2,2))(conv2)\n",
    "\n",
    "        conv3 = conv_block(pool2,base_dense*4,BatchNorm=True)\n",
    "        pool3 = MaxPooling2D((2,2))(conv3)\n",
    "\n",
    "        conv4 = conv_block(pool3,base_dense*8,BatchNorm=True)\n",
    "        pool4 = MaxPooling2D((2,2))(conv4)\n",
    "\n",
    "        #middle\n",
    "        convm = conv_block(pool4,base_dense*16,BatchNorm=True)\n",
    "\n",
    "        #deconvolution\n",
    "        deconv1 = Conv2DTranspose(base_dense*8,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(convm)\n",
    "        uconv1=concatenate([deconv1,conv4])\n",
    "        uconv1=conv_block(uconv1,base_dense*8,BatchNorm=True)\n",
    "\n",
    "        deconv2 = Conv2DTranspose(base_dense*4,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv1)\n",
    "        uconv2=concatenate([deconv2,conv3])\n",
    "        uconv2=conv_block(uconv2,base_dense*4,BatchNorm=True)\n",
    "\n",
    "        deconv3= Conv2DTranspose(base_dense*2,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv2)\n",
    "        uconv3=concatenate([deconv3,conv2])\n",
    "        uconv3=conv_block(uconv3,base_dense*2,BatchNorm=True)\n",
    "\n",
    "        deconv4 = Conv2DTranspose(base_dense,(3,3),strides=(2,2),padding=\"same\",activation=\"relu\")(uconv3)\n",
    "        uconv4=concatenate([deconv4,conv1])\n",
    "        uconv4=conv_block(uconv4,base_dense,BatchNorm=True)\n",
    "        \n",
    "    output_layer=Conv2D(1,(1,1),padding='same',activation='sigmoid',name='output_layer')(uconv4)\n",
    "    \n",
    "    model=Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit_generator(model,train_generator,x_test,y_test,loss_function, optimizer,metrics,batch_size,n_epochs,STEP_SIZE_TRAIN):\n",
    "    \n",
    "    model.compile(loss=loss_function,optimizer = optimizer,metrics=[metrics])\n",
    "\n",
    "\n",
    "    \n",
    "  \n",
    "    model_hist=model.fit_generator(generator=train_generator,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        validation_data=(x_test,y_test)\n",
    "                        ,epochs=n_epochs,verbose=1)\n",
    "    return model_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_fit(model,loss_function, optimizer,metrics,x_train,y_train,x_test,y_test,batch_size,n_epochs):\n",
    "    clf=model\n",
    "    clf.compile(loss=loss_function,optimizer = optimizer,metrics=[metrics])\n",
    "    clf_hist=clf.fit(x_train,y_train,batch_size,n_epochs,validation_data=(x_test, y_test))\n",
    "    return clf_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + K.epsilon()) / (K.sum(y_true_f) + K.sum(y_pred_f) + K.epsilon())\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_curves_plot(model_hist):\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(model_hist.history[\"loss\"], label=\"loss\")\n",
    "    plt.plot(model_hist.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.plot( np.argmin(model_hist.history[\"val_loss\"]),\n",
    "     np.min(model_hist.history[\"val_loss\"]),\n",
    "     marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss Value\")\n",
    "    plt.legend();\n",
    "    \n",
    "def accuracy_curves_plot(model_hist,metrics):\n",
    "    get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "    \n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.plot(model_hist.history[metrics], label=\"accuracy\")\n",
    "    plt.plot(model_hist.history[\"val_\"+metrics], label=\"val_accuracy\")\n",
    "    plt.plot( np.argmax(model_hist.history[\"val_\"+metrics]),\n",
    "     np.max(model_hist.history[\"val_\"+metrics]),\n",
    "     marker=\"x\", color=\"r\", label=\"best model\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy Value\")\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + K.epsilon()) / (K.sum(y_pred_f) + K.epsilon())\n",
    "\n",
    "def recall(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + K.epsilon()) / (K.sum(y_true_f) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "def load_streamlines(dataPath, subject_ids, bundles, n_tracts_per_bundle):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(subject_ids)):\n",
    "        for c in range((len(bundles))):\n",
    "            filename = dataPath + subject_ids[i] + '/' + bundles[c] + '.trk' \n",
    "            tfile = nib.streamlines.load(filename)\n",
    "            streamlines = tfile.streamlines\n",
    "            n_tracts_total = len(streamlines)\n",
    "            ix_tracts = np.random.choice(range(n_tracts_total), n_tracts_per_bundle, replace=False)\n",
    "\n",
    "            streamlines_data = streamlines.data \n",
    "            streamlines_offsets = streamlines._offsets\n",
    "            for j in range(n_tracts_per_bundle):\n",
    "                ix_j = ix_tracts[j]\n",
    "                offset_start = streamlines_offsets[ix_j] \n",
    "                if ix_j < (n_tracts_total - 1):\n",
    "                    offset_end = streamlines_offsets[ix_j + 1]\n",
    "                    streamline_j = streamlines_data[offset_start:offset_end] \n",
    "                else:\n",
    "                    streamline_j = streamlines_data[offset_start:]\n",
    "                X.append(np.asarray(streamline_j))\n",
    "                y.append(c)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to serch for the longest bundles\n",
    "def search_len_max(liste):\n",
    "    len_max=liste[0].shape[0]\n",
    "    for i in range(1,len(liste)):\n",
    "        if liste[i].shape[0]>len_max:\n",
    "            len_max=liste[i].shape[0]\n",
    "    return len_max\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence \n",
    "class MyBatchGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size=1, shuffle=True):\n",
    "        self.X = X \n",
    "        self.y = y\n",
    "        self.batch_size = batch_size \n",
    "        self.shuffle = shuffle \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        'Get number of batches per epoch'\n",
    "        return int(np.floor(len(self.y)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.__data_generation(index)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Shuffle indexes after each epoch' \n",
    "        self.indexes = np.arange(len(self.y)) \n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __data_generation(self, index):\n",
    "        Xb = np.empty((self.batch_size, *self.X[index].shape)) \n",
    "        yb = np.empty((self.batch_size, 1))\n",
    "        for s in range(0, self.batch_size):\n",
    "            Xb[s] = self.X[index]\n",
    "            yb[s] = self.y[index] \n",
    "        return Xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_class(units,dr,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units, return_sequences=True,stateful=True), batch_input_shape=(1,None,3)))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,return_sequences=True,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,return_sequences=True,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_class_padded(units,dr,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units, return_sequences=True,stateful=True), batch_input_shape=(batch_size,len_max,3)))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,return_sequences=True,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,return_sequences=True,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_simple(units,batch_size,input_size,input_dim,dr):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(units, return_sequences=True,stateful=True), batch_input_shape=(batch_size,input_size,input_dim)))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,return_sequences=True,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,return_sequences=True,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(LSTM(units,stateful=True))\n",
    "    model.add(Dropout(dr))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    #model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet_batch_lstm(base_dense,img_w,img_h,img_ch,dropout=False,dr=0.2):\n",
    "    input_size = (img_w, img_h,img_ch)\n",
    "    input_layer = Input(shape=input_size, name='input_layer')\n",
    "    \n",
    "    if dropout==True:\n",
    "        conv1 = conv_block(input_layer,base_dense,BatchNorm=True)\n",
    "        pool1 = MaxPooling2D((2,2))(conv1)\n",
    "        pool1 = Dropout(dr)(pool1)\n",
    "\n",
    "        conv2 = conv_block(pool1,base_dense*2,BatchNorm=True)\n",
    "        pool2 = MaxPooling2D((2,2))(conv2)\n",
    "        pool2 = Dropout(dr)(pool2)\n",
    "\n",
    "        conv3 = conv_block(pool2,base_dense*4,BatchNorm=True)\n",
    "        pool3 = MaxPooling2D((2,2))(conv3)\n",
    "        pool3 = Dropout(dr)(pool3)\n",
    "\n",
    "        conv4 = conv_block(pool3,base_dense*8,BatchNorm=True)\n",
    "        pool4 = MaxPooling2D((2,2))(conv4)\n",
    "        pool4 = Dropout(dr)(pool4)\n",
    "\n",
    "        #middle\n",
    "        convm = conv_block(pool4,base_dense*16,BatchNorm=True)\n",
    "\n",
    "        # up-sampling:\n",
    "        deconv1 = Conv2DTranspose(base_dense * 8, (3, 3), strides=(2, 2), padding='same')(convm)\n",
    "        # reshaping:\n",
    "        x1 = Reshape(target_shape=(1, np.int32(img_size / 8), np.int32(img_size / 8), base_dense * 8))(conv4)\n",
    "        # LSTM:\n",
    "        x2 = Reshape(target_shape=(1, np.int32(img_size / 8), np.int32(img_size / 8), base_dense * 8))(deconv1)\n",
    "        # concatenation:\n",
    "        uconv1 = concatenate([x1, x2], axis=1)\n",
    "        uconv1= Dropout(dr)(uconv1)\n",
    "        uconv1 = ConvLSTM2D(base_dense*4, (3, 3), padding='same', return_sequences=False, go_backwards=True)(uconv1)\n",
    "        # the function conv_block implements the usual convolutional block with 2 convolutional layer:\n",
    "        uconv1 = conv_block(deconv1, base_dense=base_dense * 8,   BatchNorm= True)\n",
    "        \n",
    "        \n",
    "        # up-sampling:\n",
    "        deconv2 = Conv2DTranspose(base_dense * 4, (3, 3), strides=(2, 2), padding='same')(uconv1)\n",
    "        # reshaping:\n",
    "        x3 = Reshape(target_shape=(1, np.int32(img_size / 4), np.int32(img_size / 4), base_dense * 4))(conv3)\n",
    "        # LSTM:\n",
    "        x4 = Reshape(target_shape=(1, np.int32(img_size / 4), np.int32(img_size / 4), base_dense * 4))(deconv2)\n",
    "        # concatenation:\n",
    "        uconv2 = concatenate([x3, x4], axis=1)\n",
    "        uconv2=Dropout(dr)(uconv2)\n",
    "        uconv2 = ConvLSTM2D(base_dense*4, (3, 3), padding='same', return_sequences=False, go_backwards=True)(uconv2)\n",
    "        # the function conv_block implements the usual convolutional block with 2 convolutional layer:\n",
    "        uconv2 = conv_block(uconv2, base_dense=base_dense * 2,   BatchNorm= True)\n",
    "\n",
    "         # up-sampling:\n",
    "        deconv3 = Conv2DTranspose(base_dense * 2, (3, 3), strides=(2, 2), padding='same')(uconv2)\n",
    "        # reshaping:\n",
    "        x5 = Reshape(target_shape=(1, np.int32(img_size / 2), np.int32(img_size / 2), base_dense * 2))(conv2)\n",
    "        # LSTM:\n",
    "        x6 = Reshape(target_shape=(1, np.int32(img_size / 2), np.int32(img_size / 2), base_dense * 2))(deconv3)\n",
    "        # concatenation:\n",
    "        uconv3 = concatenate([x5, x6], axis=1)\n",
    "        uconv3 = Dropout(dr)(uconv3)\n",
    "        uconv3 = ConvLSTM2D(base_dense*2, (3, 3), padding='same', return_sequences=False, go_backwards=True)(uconv3)\n",
    "        # the function conv_block implements the usual convolutional block with 2 convolutional layer:\n",
    "        uconv3 = conv_block(uconv3, base_dense=base_dense * 2,   BatchNorm= True)\n",
    "        \n",
    "    \n",
    "        # up-sampling:\n",
    "        deconv4 = Conv2DTranspose(base_dense, (3, 3), strides=(2, 2), padding='same')(uconv3)\n",
    "        # reshaping:\n",
    "        x7 = Reshape(target_shape=(1, np.int32(img_size), np.int32(img_size), base_dense))(conv1)\n",
    "        # LSTM:\n",
    "        x8 = Reshape(target_shape=(1, np.int32(img_size), np.int32(img_size), base_dense))(deconv4)\n",
    "        # concatenation:\n",
    "        uconv4 = concatenate([x7, x8], axis=1)\n",
    "        uconv4 = Dropout(dr)(uconv4)\n",
    "        uconv4 = ConvLSTM2D(base_dense*2, (3, 3), padding='same', return_sequences=False, go_backwards=True)(uconv4)\n",
    "        # the function conv_block implements the usual convolutional block with 2 convolutional layer:\n",
    "        uconv4 = conv_block(uconv4, base_dense=base_dense,   BatchNorm= True)\n",
    "\n",
    "        \n",
    "    output_layer=Conv2D(1,(1,1),padding='same',activation='sigmoid',name='output_layer')(uconv4)\n",
    "    \n",
    "    model=Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + K.epsilon()) / (K.sum(y_pred_f) + K.epsilon())\n",
    "\n",
    "def recall(y_true,y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + K.epsilon()) / (K.sum(y_true_f) + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
